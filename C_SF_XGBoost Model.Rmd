---
title: "EL Model Complaint"
author: "Justin Hubbard"
date: "Apr 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#rm(list=ls())
library(Hmisc)
library(ISLR)
library(sqldf)
library(doBy)
library(ggplot2)
library(rmarkdown)
library(dplyr)
library(gmodels)
library(xgboost)
library(gbm)
library(pROC)
library(ineq)
library(scorecard)
library(dummies)
library(data.table)
library(Matrix)
library(pdp)
library(caret)
library(haven)
library(tictoc)
library(foreign)
```

###Data Analysis
###Data Pre Processing
Function for datapreprocessing and creating Dummy Variables.

```{r, include=FALSE}
#Functions for analysis

data_trans<- function(x,q1,q2,q3=NA)
{ a=quantile(x,c(q1),na.rm=T)
  b=quantile(x,c(q2),na.rm=T)
  y=ifelse(x>=b,b,x)
  c=ifelse(x<=a,a,y) 
  ifelse(is.na(x)==TRUE,q3,c)
}

data_quant<-function(x,q3=NA)
{ a=quantile(x,c(0.01),na.rm=T)
  b=quantile(x,c(0.99),na.rm=T)
  y=ifelse(x>=b,b,x)
  c=ifelse(x<=a,a,y) 
  ifelse(is.na(x)==TRUE,q3,c)
}

var_type<- function(x){
  c<-length(names(x)[which(lapply(x,class)%in%c("character"))])
  f<-length(names(x)[which(lapply(x,class)%in%c("factor"))])
  l<-length(names(x)[which(lapply(x,class)%in%c("logical"))])
  n<-length(names(x)[which(lapply(x,class)%in%c("numeric"))])
  i<-length(names(x)[which(lapply(x,class)%in%c("integer"))])
  p<-length(names(x)[which(lapply(x,class)%in%c("POSIXct"))])
  P<-length(names(x)[which(lapply(x,class)%in%c("POSIXt"))])
  tab_var<-cbind(c,f,l,n,i,p,P)
  colnames(tab_var)<-c("character","factor","logical","numeric","integer","POSIXct","POSIXt")
  knitr::kable(tab_var)}

data_proc<- function(x){
  x$random=runif(nrow(x),0,1)
  x$LGDrandom=ifelse(x$LGD>x$random,1,0)
  x$meanLGD=ifelse(x$LGD>mean(x$LGD),1,0)
  x<- subset(x, select = -c(SSN,CUSTNBR,MIGRATEDDEALNBR,TRACK_ID,FI_EEE_IN_REQUEST_ID,DEALNBR,FD_REQUEST_DTTM, 
                            LOAN_REQUEST_DTTM,LOAN_ORG_DATE,MONTHENDDT,DEAL_DT, COMPANY_FIRSTDT,PRODUCT_FIRSTDT,
                            MONTH_END_DATE, DEF_DT,PRE_LOAN_DEAL_DT_LAST, DOB, GROSSPAYPERCHECK,HOUSING_STATUS,
                            LOAN_REQUEST_ID, INA_TOTAL, DM_FLAG,MODEL_SCORE,BALANCE_AS_OF_3_22_19,FEE,COMPANY_FIRSTDT,
                            PRE_LOAN_DEAL_DT_LAST,DEAL_SNAP_DIFFERENCE, MODEL_TYPE,LOAN_SNAP_DELINQ_DAYS, 
                            CUST_TOTAL_DELINQ_DAYS_IN_180,CUST_DAYS_IN_DELINQ_STATUS180,
                            DEALNUM_OPEN_IN_60,PDL_DEALNUM_OPEN_IN_120,PDL_DEALNUM_OPEN_IN_180,CHANNELCD,ONLINE_CHANNEL))

x$GROSS_INCOME_AMT<- data_trans(x$GROSS_INCOME_AMT,0.00001,0.998)
x$NET_INCOME_AMT<- data_trans(x$NET_INCOME_AMT,0.0001,0.99)
x$NETPAYPERCHECK <- data_trans(x$NETPAYPERCHECK,0.00001,0.995)
x$LOAN_APP_GMI <- data_trans(x$LOAN_APP_GMI ,0.00001,0.995)
x$LOAN_APP_NMI<- data_trans(x$LOAN_APP_NMI ,0.00001,0.998)
x$Gross_Income_Change<-x$GROSS_INCOME_AMT - x$LOAN_APP_GMI
x$Net_Income_Change<-x$NET_INCOME_AMT - x$LOAN_APP_NMI
x$Net_Income_Change<- data_trans(x$Net_Income_Change ,0.001,1)
x$AA_CMOB_DEAL <- data_trans(x$AA_CMOB_DEAL,0.001,1)
x$PROD_CMOB_DEAL <- data_trans(x$PROD_CMOB_DEAL,0.001,1)
x$PROD_CMOB_SNAP<-ifelse(x$PROD_CMOB_SNAP<0,0,x$PROD_CMOB_SNAP)
x$LMOB<-ifelse(x$LMOB<0,0,x$PROD_CMOB_SNAP)
x$INA_MAX<- data_trans(x$INA_MAX,0.01,1)
x$LOAN_APP_PAYROLL<-ifelse(is.na(x$LOAN_APP_PAYROLL)==TRUE,"N",x$LOAN_APP_PAYROLL)

num_var<-  c("PDL_DEALNUM_OPEN_IN_60","DEALNUM_DEF_IN_60","DEALNUM_DELINQ7_IN_60","CUST_TOTAL_DELINQ_DAYS_IN_60",
             "CUST_POSIT_DELINQ_DAYS_IN_60","CUST_DAYS_IN_DELINQ_STATUS60","DEALNUM_OPEN_IN_90", "PDL_DEALNUM_OPEN_IN_90",
             "DEALNUM_DEF_IN_90","DEALNUM_DELINQ7_IN_90","CUST_TOTAL_DELINQ_DAYS_IN_90" ,"CUST_POSIT_DELINQ_DAYS_IN_90",
             "CUST_DAYS_IN_DELINQ_STATUS90", "DEALNUM_OPEN_IN_120","DEALNUM_DEF_IN_120","DEALNUM_DELINQ7_IN_120",
             "CUST_TOTAL_DELINQ_DAYS_IN_120","CUST_POSIT_DELINQ_DAYS_IN_120","CUST_DAYS_IN_DELINQ_STATUS120",
             "DEALNUM_OPEN_IN_180", "DEALNUM_DEF_IN_180","DEALNUM_DELINQ7_IN_180","CUST_POSIT_DELINQ_DAYS_IN_180",
             "DEALNUM_OPEN_IN_365","PDL_DEALNUM_OPEN_IN_365","DEALNUM_DEF_IN_365","DEALNUM_DELINQ7_IN_365",
             "CUST_TOTAL_DELINQ_DAYS_IN_365", "CUST_POSIT_DELINQ_DAYS_IN_365","CUST_DAYS_IN_DELINQ_STATUS365","LMOB",
             "MODEL_SCORE_BIN", "DAYS_SINCE_LAST_ORG","LOAN_APP_GPI", "LOAN_APP_NMI" )

x[num_var]<-lapply(x[num_var], data_quant)
x$AGE <- ifelse(x$AGE<19,19, ifelse(x$AGE>100,100,x$AGE))
dummy.data.frame(data.table(x),
                               names=names(train)[which(lapply(x,class)%in%c("character","factor"))], sep=".",verbose=T)}
```
###Data Transformation.
percent(<data>)
missing(<data>)
quantile(<data>,prob =c(0.00001,0.001,0.01,0.5,0.98,0.99,0.995,0.9995,0.9998,1),na.rm=T) were used to analyze any missing values, outliers and data_trans and data_quant functions were used to impute and transform the data.

### Dataset : com_compliant_attributes_1516s
Complaint data sample from 2015-2016 with similar properties of the original dataset.
The original SAS file is about 10gb with 10,643,248 rows.
Of this only 544,555 obs were selected due to computatational limitations.

```{r}
open_data <- read_sas("Z:/SAS Data/user/jvontela/Data/com_compliant_attributes_1516s.sas7bdat")
open_data <- open_data %>%
              filter(CHANNELCD == "STOREFRONT")
open_dataDUM <- data_proc(open_data)
#Testing and training dataset
set.seed(17)
index <- sample(seq_len(nrow(open_dataDUM)), size = floor(0.75 * nrow(open_data)))
trainDUM <- open_dataDUM[index, ]
testDUM <- open_dataDUM[-index, ]
train<- open_data[index, ]
test <- open_data[-index, ]
rm(open_data)
rm(open_dataDUM)

```
###Parameters and Boosted algorthims
First default parameters for each parameters is set ans best nround is calculated for the model using xgb.cv function.

```{r}

params=list(  max_depth = 6
            , eta = 0.06
            , nthread = 6
            , subsample = 0.5
            , colsample_bytree = 0.8
            , min_child_weight = 100
            , early.stop.rounds = 30
            , objective = "reg:logistic"
            , seed = 17)

dropvars=c("PD","LGDrandom","meanLGD","random","LGD")

bst <- xgboost(   data = as.matrix(select(trainDUM,-one_of(dropvars)))
               , label = as.matrix(select(trainDUM,LGDrandom))
               , params = params
               , eval_metric = "auc"
               , nrounds = 2000
               , verbose = 1
               , maximize = F
               , print_every_n = 300)

save(bst, file = "Z:/SAS Data/user/jvontela/Allowance/ML Model/Compliant/Comp_SF.rda")

tic("PRED")
test$pred<-predict( bst
                   , as.matrix(select(testDUM,-one_of(dropvars)))
                   , outputmargin = F
                   , ntreelimit = min(bst$best_iteration,bst$niter)
                   , predcontrib = F)
toc()

RMSE(test$pred,test$LGD)
#auc(test$LGD,test$pred)

```
Select the important attributes of the dataset.
Refit the model and check for accuracy.

```{r}

imp_mat <- xgb.importance (model = bst)
thres <- imp_mat[1:20]
thres$gainsum <- cumsum(thres$Gain)
new_var <- unique(thres$Feature)

#monotone_contstraints=monotonicity,
bst_fin <- xgboost(  data = as.matrix(select(trainDUM,one_of(new_var)))
                    , label=as.matrix(select(trainDUM,LGDrandom))
                    , params=params
                    , eval_metric="auc"
                    , nrounds = 2000
                    , verbose=1
                    , nfold=2
                    , maximize=F
                    , print_every_n = 500)

test$pred<-predict( bst_fin
                   , as.matrix(select(testDUM,one_of(new_var)))
                   , outputmargin = F
                   , ntreelimit = min(bst$best_iteration,bst$niter)
                   , predcontrib = F)

RMSE(test$pred,test$LGD)
#auc(test$LGD,test$pred)

```

#Partial Dependence Plots
```{r}

tic("Plots")
for(i in 1:nrow(imp)){
  jpeg(paste("imp_",i,"_",imp$Feature[i],"_pdp.jpeg",sep=""))
  
  p1<- partial(   bst
                , pred.var=imp$Feature[i]
                , plot=T
                , train=select(trainDUM[sample(nrow(trainDUM),100000),],-one_of(dropvars))
                , type="regression")
  
  p2<- qplot(  trainDUM[,imp$Feature[i]]
             , geom="histogram"
             , xlab=paste(imp$Feature[i])
             , main=paste("All data histogram of "
             , imp$Feature[i]))
  
  grid.arrange(p1,p2,ncol=2)
  
  dev.off()}

```

Out of sample RMSE Calculation
```{r}

#Out of sample AUC
data18 <- read_sas("Z:\\SAS Data\\user\\jli\\Allowance revisit\\com_compliant_18.sas7bdat")
data18DUM <- data_proc(data18)

ol18$pred <- predict(  bst
                      , as.matrix(select(data18DUM,-one_of(dropvars)))
                      ,outputmargin=F,       ntreelimit=min(bst$best_iteration,bst$niter),predcontrib=F)
RMSE(ol18$pred,ol18$PD)
auc(ol18DUM$randomPD,ol18$pred)
#rm(data17DUM)
#rm(data17)

```
